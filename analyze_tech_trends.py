#!/usr/bin/env python3
"""
æŠ€æœ¯éœ€æ±‚è¶‹åŠ¿åˆ†æžå·¥å…·
åˆ†æžèŒä½æè¿°ï¼ˆJDï¼‰ä¸­çš„æŠ€æœ¯æ ˆã€æŠ€èƒ½è¦æ±‚ç­‰
"""

import sqlite3
import re
from collections import Counter
from typing import Dict, List, Tuple
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class TechTrendAnalyzer:
    """åˆ†æžèŒä½æè¿°ä¸­çš„æŠ€æœ¯è¶‹åŠ¿"""
    
    def __init__(self, db_path='job_scraper.db'):
        self.db_path = db_path
        
        # å®šä¹‰è¦è·Ÿè¸ªçš„æŠ€æœ¯å…³é”®è¯
        self.tech_keywords = {
            # ç¼–ç¨‹è¯­è¨€
            'Python': ['python'],
            'Java': ['java', r'\bjava\b'],
            'JavaScript': ['javascript', 'js'],
            'TypeScript': ['typescript', 'ts'],
            'C#': ['c#', 'c-sharp', 'csharp'],
            'C++': ['c++', 'cpp'],
            'Go': [r'\bgo\b', 'golang'],
            'Rust': ['rust'],
            'PHP': ['php'],
            'Ruby': ['ruby'],
            'Swift': ['swift'],
            'Kotlin': ['kotlin'],
            'R': [r'\b r \b', r'\br\b'],
            'Scala': ['scala'],
            
            # å‰ç«¯æ¡†æž¶
            'React': ['react', 'react.js', 'reactjs'],
            'Angular': ['angular'],
            'Vue': ['vue', 'vue.js', 'vuejs'],
            'Next.js': ['next.js', 'nextjs'],
            'Svelte': ['svelte'],
            
            # åŽç«¯æ¡†æž¶
            'Node.js': ['node.js', 'nodejs', 'node'],
            'Django': ['django'],
            'Flask': ['flask'],
            'Spring': ['spring boot', 'spring'],
            '.NET': ['.net', 'dotnet', 'asp.net'],
            'Express': ['express.js', 'express'],
            'FastAPI': ['fastapi'],
            
            # æ•°æ®åº“
            'PostgreSQL': ['postgresql', 'postgres'],
            'MySQL': ['mysql'],
            'MongoDB': ['mongodb', 'mongo'],
            'Redis': ['redis'],
            'SQL Server': ['sql server', 'mssql'],
            'Oracle': ['oracle db', 'oracle'],
            'SQLite': ['sqlite'],
            'Elasticsearch': ['elasticsearch', 'elastic'],
            
            # äº‘å¹³å°
            'AWS': ['aws', 'amazon web services'],
            'Azure': ['azure', 'microsoft azure'],
            'GCP': ['gcp', 'google cloud'],
            'Alibaba Cloud': ['alibaba cloud', 'aliyun'],
            
            # DevOps & å·¥å…·
            'Docker': ['docker'],
            'Kubernetes': ['kubernetes', 'k8s'],
            'Jenkins': ['jenkins'],
            'GitLab CI': ['gitlab ci', 'gitlab-ci'],
            'GitHub Actions': ['github actions'],
            'Terraform': ['terraform'],
            'Ansible': ['ansible'],
            
            # æ•°æ®ç§‘å­¦ & AI
            'Machine Learning': ['machine learning', 'ml'],
            'Deep Learning': ['deep learning', 'dl'],
            'TensorFlow': ['tensorflow'],
            'PyTorch': ['pytorch'],
            'Pandas': ['pandas'],
            'NumPy': ['numpy'],
            'Scikit-learn': ['scikit-learn', 'sklearn'],
            'Data Science': ['data science'],
            'AI': ['artificial intelligence', r'\bai\b'],
            
            # å…¶ä»–æŠ€æœ¯
            'REST API': ['rest api', 'restful'],
            'GraphQL': ['graphql'],
            'Microservices': ['microservices', 'micro-services'],
            'CI/CD': ['ci/cd', 'continuous integration'],
            'Agile': ['agile', 'scrum'],
            'Git': ['git', 'github', 'gitlab'],
        }
    
    def get_jobs_with_descriptions(self) -> List[Dict]:
        """èŽ·å–æ‰€æœ‰åŒ…å«JDçš„èŒä½"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, title, company, description, category, source, created_at
            FROM jobs
            WHERE description != '' AND description IS NOT NULL
            ORDER BY created_at DESC
        """)
        
        jobs = [dict(row) for row in cursor.fetchall()]
        conn.close()
        
        return jobs
    
    def count_tech_mentions(self, jobs: List[Dict]) -> Counter:
        """ç»Ÿè®¡å„æŠ€æœ¯åœ¨JDä¸­å‡ºçŽ°çš„æ¬¡æ•°"""
        tech_counter = Counter()
        
        for job in jobs:
            description = job['description'].lower()
            
            # æ£€æŸ¥æ¯ä¸ªæŠ€æœ¯å…³é”®è¯
            for tech_name, patterns in self.tech_keywords.items():
                for pattern in patterns:
                    if re.search(pattern, description, re.IGNORECASE):
                        tech_counter[tech_name] += 1
                        break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†ï¼Œé¿å…é‡å¤è®¡æ•°
        
        return tech_counter
    
    def analyze_by_category(self, jobs: List[Dict]) -> Dict[str, Counter]:
        """æŒ‰èŒä½ç±»åˆ«åˆ†æžæŠ€æœ¯éœ€æ±‚"""
        category_tech = {}
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        category_jobs = {}
        for job in jobs:
            category = job.get('category', 'Unknown')
            if category not in category_jobs:
                category_jobs[category] = []
            category_jobs[category].append(job)
        
        # åˆ†æžæ¯ä¸ªç±»åˆ«
        for category, cat_jobs in category_jobs.items():
            category_tech[category] = self.count_tech_mentions(cat_jobs)
        
        return category_tech
    
    def analyze_by_source(self, jobs: List[Dict]) -> Dict[str, Counter]:
        """æŒ‰æ•°æ®æºåˆ†æžæŠ€æœ¯éœ€æ±‚"""
        source_tech = {}
        
        # æŒ‰æ¥æºåˆ†ç»„
        source_jobs = {}
        for job in jobs:
            source = job.get('source', 'seek')
            if source not in source_jobs:
                source_jobs[source] = []
            source_jobs[source].append(job)
        
        # åˆ†æžæ¯ä¸ªæ¥æº
        for source, src_jobs in source_jobs.items():
            source_tech[source] = self.count_tech_mentions(src_jobs)
        
        return source_tech
    
    def print_top_technologies(self, tech_counter: Counter, top_n=20):
        """æ‰“å°æœ€çƒ­é—¨çš„æŠ€æœ¯"""
        logger.info(f"\nðŸ”¥ Top {top_n} çƒ­é—¨æŠ€æœ¯:")
        logger.info("=" * 60)
        
        for i, (tech, count) in enumerate(tech_counter.most_common(top_n), 1):
            percentage = (count / len(self.get_jobs_with_descriptions())) * 100
            bar = 'â–ˆ' * int(percentage / 2)
            logger.info(f"{i:2d}. {tech:20s} | {count:3d} æ¬¡ ({percentage:5.1f}%) {bar}")
    
    def print_category_analysis(self, category_tech: Dict[str, Counter], top_n=10):
        """æ‰“å°æŒ‰ç±»åˆ«çš„æŠ€æœ¯éœ€æ±‚åˆ†æž"""
        logger.info("\nðŸ“Š æŒ‰èŒä½ç±»åˆ«åˆ†æž:")
        logger.info("=" * 60)
        
        for category, tech_counter in sorted(category_tech.items()):
            if not tech_counter:
                continue
            
            logger.info(f"\nã€{category}ã€‘ - {sum(tech_counter.values())} ä¸ªæŠ€æœ¯æåŠ")
            for i, (tech, count) in enumerate(tech_counter.most_common(top_n), 1):
                logger.info(f"  {i:2d}. {tech:20s} - {count:3d} æ¬¡")
    
    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´çš„æŠ€æœ¯è¶‹åŠ¿æŠ¥å‘Š"""
        logger.info("\n" + "=" * 60)
        logger.info("ðŸš€ æ–°è¥¿å…°ITå¸‚åœºæŠ€æœ¯éœ€æ±‚åˆ†æžæŠ¥å‘Š")
        logger.info("=" * 60)
        
        # èŽ·å–æ•°æ®
        jobs = self.get_jobs_with_descriptions()
        
        if not jobs:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ…å«JDçš„èŒä½æ•°æ®ï¼")
            logger.info("\næç¤ºï¼šè¿è¡Œä»¥ä¸‹å‘½ä»¤æŠ“å–JDï¼š")
            logger.info("  cd scrapers && python integrated_scraper.py --sources seek --fetch-descriptions --max-descriptions 50")
            return
        
        logger.info(f"\nðŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        logger.info(f"  - æ€»èŒä½æ•°ï¼ˆå«JDï¼‰: {len(jobs)}")
        
        # æŒ‰æ¥æºç»Ÿè®¡
        source_counts = Counter(job['source'] for job in jobs)
        logger.info(f"  - æ•°æ®æºåˆ†å¸ƒ: {dict(source_counts)}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_counts = Counter(job['category'] for job in jobs)
        logger.info(f"  - èŒä½ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in category_counts.most_common():
            logger.info(f"    â€¢ {category}: {count}")
        
        # æ•´ä½“æŠ€æœ¯éœ€æ±‚åˆ†æž
        overall_tech = self.count_tech_mentions(jobs)
        self.print_top_technologies(overall_tech, top_n=20)
        
        # æŒ‰ç±»åˆ«åˆ†æž
        category_tech = self.analyze_by_category(jobs)
        self.print_category_analysis(category_tech, top_n=10)
        
        # æŠ€æœ¯æ ˆç»„åˆåˆ†æž
        logger.info("\nðŸ”— å¸¸è§æŠ€æœ¯æ ˆç»„åˆ:")
        logger.info("=" * 60)
        self.analyze_tech_stacks(jobs)
        
        # æ–°å…´æŠ€æœ¯è¶‹åŠ¿
        logger.info("\nðŸŒŸ æ–°å…´æŠ€æœ¯å…³æ³¨åº¦:")
        logger.info("=" * 60)
        emerging_tech = {k: v for k, v in overall_tech.items() 
                        if k in ['Rust', 'Go', 'Kubernetes', 'GraphQL', 'Next.js', 
                                'FastAPI', 'Svelte', 'PyTorch', 'TensorFlow']}
        for tech, count in sorted(emerging_tech.items(), key=lambda x: x[1], reverse=True):
            if count > 0:
                logger.info(f"  â€¢ {tech:20s} - {count:3d} æ¬¡")
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… åˆ†æžå®Œæˆï¼")
        logger.info("=" * 60)
    
    def analyze_tech_stacks(self, jobs: List[Dict]):
        """åˆ†æžå¸¸è§çš„æŠ€æœ¯æ ˆç»„åˆ"""
        # å®šä¹‰ä¸€äº›æŠ€æœ¯æ ˆç»„åˆ
        stacks = {
            'MERN (MongoDB + Express + React + Node)': ['mongodb', 'express', 'react', 'node'],
            'MEAN (MongoDB + Express + Angular + Node)': ['mongodb', 'express', 'angular', 'node'],
            'Django + PostgreSQL + React': ['django', 'postgres', 'react'],
            'Spring Boot + MySQL': ['spring', 'mysql'],
            '.NET + SQL Server': ['.net', 'sql server'],
            'Python + Machine Learning': ['python', 'machine learning'],
            'AWS + Docker + Kubernetes': ['aws', 'docker', 'kubernetes'],
        }
        
        stack_counts = Counter()
        
        for job in jobs:
            description = job['description'].lower()
            
            for stack_name, tech_list in stacks.items():
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æŠ€æœ¯éƒ½å‡ºçŽ°
                if all(any(re.search(pattern, description, re.IGNORECASE) 
                          for pattern in self.tech_keywords.get(tech, [tech.lower()]))
                      for tech in tech_list):
                    stack_counts[stack_name] += 1
        
        for stack, count in stack_counts.most_common(10):
            if count > 0:
                logger.info(f"  â€¢ {stack:45s} - {count:3d} æ¬¡")


def main():
    """ä¸»å‡½æ•°"""
    analyzer = TechTrendAnalyzer()
    analyzer.generate_report()


if __name__ == '__main__':
    main()

