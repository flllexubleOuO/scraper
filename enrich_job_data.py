#!/usr/bin/env python3
"""
ä¸°å¯Œç°æœ‰èŒä½æ•°æ® - æå–æŠ€æœ¯æ ˆå’Œå…¶ä»–ç‰¹å¾
"""

import sqlite3
import json
import logging
from tech_stack_extractor import TechStackExtractor
from tqdm import tqdm

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def enrich_jobs(db_path='job_scraper.db', batch_size=100):
    """ä¸ºç°æœ‰èŒä½æå–æŠ€æœ¯æ ˆä¿¡æ¯"""
    
    logger.info(f"ğŸ“š Opening database: {db_path}")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ–°åˆ—
    cursor.execute("PRAGMA table_info(jobs)")
    columns = [col[1] for col in cursor.fetchall()]
    
    new_columns = [
        ('tech_stack', 'TEXT'),  # JSONæ ¼å¼çš„æŠ€æœ¯æ ˆ
        ('work_type', 'TEXT'),   # remote/hybrid/onsite
        ('experience_level', 'TEXT'),  # junior/mid/senior/expert
        ('benefits', 'TEXT'),    # JSONæ•°ç»„
        ('skills_count', 'INTEGER')  # æŠ€èƒ½æ€»æ•°
    ]
    
    for col_name, col_type in new_columns:
        if col_name not in columns:
            logger.info(f"â• Adding column: {col_name}")
            cursor.execute(f"ALTER TABLE jobs ADD COLUMN {col_name} {col_type}")
    
    conn.commit()
    
    # è·å–æ‰€æœ‰æœ‰æè¿°çš„èŒä½
    cursor.execute("""
        SELECT id, title, description
        FROM jobs 
        WHERE description IS NOT NULL AND description != ''
        ORDER BY id
    """)
    
    jobs = cursor.fetchall()
    logger.info(f"ğŸ“Š Found {len(jobs)} jobs with descriptions to enrich")
    
    if not jobs:
        logger.warning("No jobs found to process!")
        return
    
    extractor = TechStackExtractor()
    updated_count = 0
    
    # å¤„ç†èŒä½
    for job in tqdm(jobs, desc="Enriching jobs"):
        job_id, title, description = job
        
        try:
            # æå–ä¿¡æ¯
            extracted = extractor.extract_all({
                'title': title or '',
                'description': description or ''
            })
            
            # æ›´æ–°æ•°æ®åº“
            cursor.execute("""
                UPDATE jobs 
                SET tech_stack = ?,
                    work_type = ?,
                    experience_level = ?,
                    benefits = ?,
                    skills_count = ?
                WHERE id = ?
            """, (
                json.dumps(extracted['tech_stack']),
                json.dumps(extracted['work_type']),
                extracted['experience_level'],
                json.dumps(extracted['benefits']),
                extracted['skills_count'],
                job_id
            ))
            
            updated_count += 1
            
            # å®šæœŸæäº¤
            if updated_count % batch_size == 0:
                conn.commit()
                logger.info(f"âœ… Processed {updated_count}/{len(jobs)} jobs")
        
        except Exception as e:
            logger.error(f"âŒ Error processing job {job_id}: {e}")
            continue
    
    # æœ€ç»ˆæäº¤
    conn.commit()
    logger.info(f"ğŸ‰ Successfully enriched {updated_count} jobs!")
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    generate_stats(cursor)
    
    conn.close()


def generate_stats(cursor):
    """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
    logger.info("\nğŸ“Š === æ•°æ®ç»Ÿè®¡æŠ¥å‘Š ===")
    
    # ç»éªŒç­‰çº§åˆ†å¸ƒ
    cursor.execute("""
        SELECT experience_level, COUNT(*) 
        FROM jobs 
        WHERE experience_level IS NOT NULL
        GROUP BY experience_level
        ORDER BY COUNT(*) DESC
    """)
    
    logger.info("\nç»éªŒç­‰çº§åˆ†å¸ƒ:")
    for level, count in cursor.fetchall():
        logger.info(f"  {level}: {count}")
    
    # å·¥ä½œç±»å‹åˆ†å¸ƒ
    cursor.execute("""
        SELECT work_type, COUNT(*) 
        FROM jobs 
        WHERE work_type IS NOT NULL AND work_type != '[]'
        GROUP BY work_type
        ORDER BY COUNT(*) DESC
        LIMIT 10
    """)
    
    logger.info("\nå·¥ä½œç±»å‹åˆ†å¸ƒ:")
    for work_type, count in cursor.fetchall():
        try:
            types = json.loads(work_type)
            logger.info(f"  {', '.join(types)}: {count}")
        except:
            continue
    
    # å¹³å‡æŠ€èƒ½æ•°
    cursor.execute("""
        SELECT AVG(skills_count), MIN(skills_count), MAX(skills_count)
        FROM jobs 
        WHERE skills_count IS NOT NULL
    """)
    
    avg, min_skills, max_skills = cursor.fetchone()
    logger.info(f"\næŠ€èƒ½ç»Ÿè®¡:")
    logger.info(f"  å¹³å‡: {avg:.1f}")
    logger.info(f"  æœ€å°‘: {min_skills}")
    logger.info(f"  æœ€å¤š: {max_skills}")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Enrich job data with tech stack information')
    parser.add_argument('--db', default='job_scraper.db', help='Database path')
    parser.add_argument('--batch-size', type=int, default=100, help='Batch size for commits')
    
    args = parser.parse_args()
    
    enrich_jobs(args.db, args.batch_size)

