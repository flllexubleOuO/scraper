#!/usr/bin/env python3
"""
Job Scraper Scheduler - å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹
æ¯å¤©12:00è‡ªåŠ¨è¿è¡Œçˆ¬è™«
"""

import schedule
import time
import subprocess
import logging
from datetime import datetime
import os
import sys

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/Users/jin/scraper/scheduler.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def run_scraper():
    """è¿è¡Œçˆ¬è™«è„šæœ¬"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Starting scheduled scraping job...")
    logger.info("=" * 60)
    
    try:
        # åˆ‡æ¢åˆ°scrapersç›®å½•å¹¶è¿è¡Œçˆ¬è™«
        scraper_path = '/Users/jin/scraper/scrapers'
        scraper_script = 'integrated_scraper.py'
        
        # è¿è¡Œçˆ¬è™«ï¼šæŠ“å–æ‰€æœ‰æºï¼ŒåŒ…å«JD
        cmd = [
            sys.executable,  # ä½¿ç”¨å½“å‰Pythonè§£é‡Šå™¨
            scraper_script,
            '--sources', 'seek', 'linkedin', 'indeed',
            '--fetch-descriptions',
            '--max-descriptions', '50'
        ]
        
        logger.info(f"Executing: {' '.join(cmd)}")
        logger.info(f"Working directory: {scraper_path}")
        
        # æ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
        result = subprocess.run(
            cmd,
            cwd=scraper_path,
            capture_output=True,
            text=True,
            timeout=3600  # 1å°æ—¶è¶…æ—¶
        )
        
        # è®°å½•è¾“å‡º
        if result.stdout:
            logger.info(f"Scraper output:\n{result.stdout}")
        
        if result.stderr:
            logger.warning(f"Scraper errors:\n{result.stderr}")
        
        # æ£€æŸ¥è¿”å›ç 
        if result.returncode == 0:
            logger.info("âœ… Scraping job completed successfully!")
        else:
            logger.error(f"âŒ Scraping job failed with return code: {result.returncode}")
        
        logger.info("=" * 60)
        logger.info(f"Next run scheduled at 12:00 tomorrow")
        logger.info("=" * 60)
        
    except subprocess.TimeoutExpired:
        logger.error("âŒ Scraping job timed out after 1 hour")
    except Exception as e:
        logger.error(f"âŒ Error running scraper: {e}", exc_info=True)

def test_run():
    """æµ‹è¯•è¿è¡Œï¼ˆç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼‰"""
    logger.info("ğŸ§ª Running test scraping job...")
    run_scraper()

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ¤– Job Scraper Scheduler Started")
    logger.info("=" * 60)
    logger.info(f"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("Schedule: Every day at 12:00")
    logger.info("=" * 60)
    
    # è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©12:00è¿è¡Œ
    schedule.every().day.at("12:00").do(run_scraper)
    
    # å¦‚æœå¯åŠ¨æ—¶å·²ç»è¿‡äº†ä»Šå¤©çš„12:00ï¼Œæ˜¾ç¤ºä¸‹æ¬¡è¿è¡Œæ—¶é—´
    next_run = schedule.next_run()
    if next_run:
        logger.info(f"â° Next run scheduled at: {next_run.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        logger.info("Running in test mode (immediate execution)...")
        test_run()
        logger.info("Test completed. Scheduler will continue running...")
    
    # ä¸»å¾ªç¯
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ Scheduler stopped by user")
    except Exception as e:
        logger.error(f"âŒ Scheduler error: {e}", exc_info=True)

if __name__ == '__main__':
    main()

