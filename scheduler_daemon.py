#!/usr/bin/env python3
"""
Job Scraper Scheduler - å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹
æ¯å¤©12:00è‡ªåŠ¨è¿è¡Œçˆ¬è™«
"""

import schedule
import time
import subprocess
import logging
from datetime import datetime
import os
import sys

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_FILE = os.path.join(SCRIPT_DIR, 'scheduler.log')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def run_scraper():
    """è¿è¡Œçˆ¬è™«è„šæœ¬"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Starting scheduled scraping job...")
    logger.info("=" * 60)
    
    try:
        # åˆ‡æ¢åˆ°scrapersç›®å½•å¹¶è¿è¡Œçˆ¬è™«
        scraper_path = os.path.join(SCRIPT_DIR, 'scrapers')
        scraper_script = 'integrated_scraper.py'
        
        # è¿è¡Œçˆ¬è™«ï¼šæŠ“å–æ‰€æœ‰æºï¼ŒåŒ…å«æ‰€æœ‰JD
        cmd = [
            sys.executable,  # ä½¿ç”¨å½“å‰Pythonè§£é‡Šå™¨
            scraper_script,
            '--sources', 'seek', 'linkedin', 'indeed', 'trademe',
            '--fetch-descriptions'
            # ä¸è®¾ç½® max-descriptionsï¼ŒæŠ“å–æ‰€æœ‰èŒä½çš„JD
        ]
        
        logger.info(f"Executing: {' '.join(cmd)}")
        logger.info(f"Working directory: {scraper_path}")
        
        # æ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
        result = subprocess.run(
            cmd,
            cwd=scraper_path,
            capture_output=True,
            text=True,
            timeout=7200  # 2å°æ—¶è¶…æ—¶ï¼ˆæŠ“å–æ‰€æœ‰JDéœ€è¦æ›´å¤šæ—¶é—´ï¼‰
        )
        
        # è®°å½•è¾“å‡º
        if result.stdout:
            logger.info(f"Scraper output:\n{result.stdout}")
        
        if result.stderr:
            logger.warning(f"Scraper errors:\n{result.stderr}")
        
        # æ£€æŸ¥è¿”å›ç 
        if result.returncode == 0:
            logger.info("âœ… Scraping job completed successfully!")
            
            # çˆ¬è™«æˆåŠŸåï¼Œè‡ªåŠ¨è¿è¡Œæ•°æ®ä¸°å¯Œè„šæœ¬
            logger.info("=" * 60)
            logger.info("ğŸ”„ Running data enrichment to extract tech stack...")
            logger.info("=" * 60)
            
            try:
                enrich_cmd = [
                    sys.executable,
                    'enrich_job_data.py',
                    '--db', os.path.join(SCRIPT_DIR, 'job_scraper.db')
                ]
                
                enrich_result = subprocess.run(
                    enrich_cmd,
                    cwd=SCRIPT_DIR,
                    capture_output=True,
                    text=True,
                    timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
                )
                
                if enrich_result.returncode == 0:
                    logger.info("âœ… Data enrichment completed successfully!")
                else:
                    logger.warning(f"âš ï¸ Data enrichment failed with return code: {enrich_result.returncode}")
                    
                if enrich_result.stdout:
                    logger.info(f"Enrichment output:\n{enrich_result.stdout}")
                    
            except Exception as e:
                logger.error(f"âŒ Error running data enrichment: {e}")
        else:
            logger.error(f"âŒ Scraping job failed with return code: {result.returncode}")
        
        logger.info("=" * 60)
        logger.info(f"Next run scheduled at 12:00 tomorrow")
        logger.info("=" * 60)
        
    except subprocess.TimeoutExpired:
        logger.error("âŒ Scraping job timed out after 1 hour")
    except Exception as e:
        logger.error(f"âŒ Error running scraper: {e}", exc_info=True)

def test_run():
    """æµ‹è¯•è¿è¡Œï¼ˆç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼‰"""
    logger.info("ğŸ§ª Running test scraping job...")
    run_scraper()

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ¤– Job Scraper Scheduler Started")
    logger.info("=" * 60)
    logger.info(f"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("Schedule: Every day at 12:00")
    logger.info("=" * 60)
    
    # è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©12:00è¿è¡Œ
    schedule.every().day.at("12:00").do(run_scraper)
    
    # å¦‚æœå¯åŠ¨æ—¶å·²ç»è¿‡äº†ä»Šå¤©çš„12:00ï¼Œæ˜¾ç¤ºä¸‹æ¬¡è¿è¡Œæ—¶é—´
    next_run = schedule.next_run()
    if next_run:
        logger.info(f"â° Next run scheduled at: {next_run.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        logger.info("Running in test mode (immediate execution)...")
        test_run()
        logger.info("Test completed. Scheduler will continue running...")
    
    # ä¸»å¾ªç¯
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ Scheduler stopped by user")
    except Exception as e:
        logger.error(f"âŒ Scheduler error: {e}", exc_info=True)

if __name__ == '__main__':
    main()

